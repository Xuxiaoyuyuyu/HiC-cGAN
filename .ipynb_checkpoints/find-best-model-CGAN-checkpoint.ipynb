{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314af022-be55-487f-95ab-b0f2fbd686a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import IPython.display as display\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from models import ConvolutionalBlock, ResidualBlock\n",
    "from torch import nn\n",
    "import hickle as hkl\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.set_device(3)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        lo, hi, distance_chrome = hkl.load('./data/GM12878/test_data_half.hkl')\n",
    "        lo = lo.squeeze()\n",
    "        hi = hi.squeeze()\n",
    "        lo = np.expand_dims(lo,axis=1)\n",
    "        hi = np.expand_dims(hi,axis=1)\n",
    "        self.sample_list = []\n",
    "        for i in range(len(lo)):\n",
    "            lr = lo[i]\n",
    "            hr = hi[i]\n",
    "            dist = abs(distance_chrome[i][0])\n",
    "            label_one_hot = torch.zeros(5)\n",
    "            label_one_hot[int(dist/40)]=1\n",
    "            chrom = distance_chrome[i][1]\n",
    "            self.sample_list.append([lr, hr, label_one_hot, dist, chrom])\n",
    "        print(\"dataset loaded : \" + str(len(lo)) + '*' + str(len(lo[0])) + '*' + str(len(lo[0][0])) + '*' + str(len(lo[0][0][0])))\n",
    "    def __getitem__(self, i):\n",
    "        (lr_img, hr_img, label_one_hot, distance, chromosome) = self.sample_list[i]\n",
    "        return lr_img, hr_img, label_one_hot, distance, chromosome\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, kernel_size=3, n_channels=64, n_blocks=5):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv_block1 = ConvolutionalBlock(in_channels=6, out_channels=n_channels, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation='relu')\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(kernel_size=kernel_size, n_channels=n_channels) for i in range(n_blocks)])\n",
    "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              batch_norm=True, activation=None)\n",
    "        self.conv_block3 = ConvolutionalBlock(in_channels=n_channels, out_channels=128, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation=None)\n",
    "        self.conv_block4 = ConvolutionalBlock(in_channels=128, out_channels=256, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation=None)\n",
    "        self.conv_block5 = ConvolutionalBlock(in_channels=256, out_channels=1, kernel_size=1,\n",
    "                                              batch_norm=False, activation='tanh')\n",
    "    def forward(self, lr_imgs):\n",
    "        output = self.conv_block1(lr_imgs)  # (batch_size, 1, 40, 40)\n",
    "        residual = output\n",
    "        output = self.residual_blocks(output)\n",
    "        output = self.conv_block2(output)\n",
    "        output = output + residual\n",
    "        output = self.conv_block3(output)\n",
    "        output = self.conv_block4(output)\n",
    "        sr_imgs = self.conv_block5(output)\n",
    "        return sr_imgs\n",
    "\n",
    "def make_input(imgs, distances): #imgs batchsize*1*40*40     distances batchsize*5\n",
    "    dis = distances.unsqueeze(2).unsqueeze(3)\n",
    "    dis = dis.repeat(1,1,40,40)\n",
    "    data_input = torch.cat((imgs,dis),1)\n",
    "    return data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cce27c1-5045-4901-a7a7-8f66ba8b7358",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded : 3173*1*40*40\n"
     ]
    }
   ],
   "source": [
    "test_dataset = testDataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1,\n",
    "                                               pin_memory=True)\n",
    "generator = Generator(kernel_size=3,n_channels=64,n_blocks=5)\n",
    "generator = generator.to(device)\n",
    "mse_loss_criterion = nn.MSELoss()\n",
    "mse_loss_criterion = mse_loss_criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f34551-c056-46d5-8a18-bb5a085b2020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MSE损失h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MSE损失h'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2bdce27db7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./log_cgan.xls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MSE损失'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmse_list_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MSE损失h\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mepoch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlist_ave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MSE损失h'"
     ]
    }
   ],
   "source": [
    "num_to_test = 200\n",
    "df = pd.read_excel(\"./log_cgan.xls\", usecols=[0, 1])\n",
    "df = df.sort_values(by='MSE损失',inplace=False,ascending=True).head(num_to_test)\n",
    "mse_list_train = df[\"MSE损失\"].values.tolist()\n",
    "epoch_list = df[\"epoch\"].values.tolist()\n",
    "list_ave = []\n",
    "list_0 = []\n",
    "list_40 = []\n",
    "list_80 = []\n",
    "list_120 = []\n",
    "list_160 = []\n",
    "cnt = 0\n",
    "for epoch in epoch_list :\n",
    "    model_path = \"./result_cgan/best_checkpoint_epoch\" + str(epoch).zfill(4) + \".pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        break\n",
    "    checkpoint = torch.load(model_path)\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    generator = generator.eval()\n",
    "\n",
    "    ave_mse = []\n",
    "    MSE_0 = []\n",
    "    MSE_40 = []\n",
    "    MSE_80 = []\n",
    "    MSE_120 = []\n",
    "    MSE_160 = []\n",
    "    for i, (lr_img, hr_img, label, distance, chrom) in enumerate(test_loader):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"***开始测试***\")\n",
    "        print(\"正在测试模型：\" + str(cnt) + \"/\" + str(num_to_test))\n",
    "        print(\"正在处理样本 ： \" + str(i+1) + \"/\"+str(len(test_dataset)))\n",
    "        print(\"MSE_AVG = \" + str(np.mean(ave_mse)))\n",
    "        print(\"MSE_0   = \" + str(np.mean(MSE_0)))\n",
    "        print(\"MSE_40  = \" + str(np.mean(MSE_40)))\n",
    "        print(\"MSE_80  = \" + str(np.mean(MSE_80)))\n",
    "        print(\"MSE_120 = \" + str(np.mean(MSE_120)))\n",
    "        print(\"MSE_160 = \" + str(np.mean(MSE_160)))\n",
    "        \n",
    "        lr_img = lr_img.type(torch.FloatTensor).to(device)\n",
    "        hr_img = hr_img.type(torch.FloatTensor).to(device)\n",
    "        label = label.to(device)\n",
    "        G_input = make_input(lr_img, label)\n",
    "        with torch.no_grad():\n",
    "            sr_img = generator(G_input.detach())\n",
    "        mse = mse_loss_criterion(sr_img , hr_img).to('cpu')\n",
    "        ave_mse.append(mse)\n",
    "        if abs(distance) == 0:\n",
    "            MSE_0.append(mse)\n",
    "        elif abs(distance) == 40:\n",
    "            MSE_40.append(mse) \n",
    "        elif abs(distance) == 80:\n",
    "            MSE_80.append(mse) \n",
    "        elif abs(distance) == 120:\n",
    "            MSE_120.append(mse) \n",
    "        elif abs(distance) == 160:\n",
    "            MSE_160.append(mse)\n",
    "    list_ave.append(np.mean(ave_mse))\n",
    "    list_0.append(np.mean(MSE_0))\n",
    "    list_40.append(np.mean(MSE_40))\n",
    "    list_80.append(np.mean(MSE_80))\n",
    "    list_120.append(np.mean(MSE_120))\n",
    "    list_160.append(np.mean(MSE_160))\n",
    "print(\"***测试结束***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694e860-bf48-429d-b390-56962cba270d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\"epoch\" : epoch_list,\n",
    "        \"mse_train\" mse_list_train，\n",
    "        \"mse_average_test\" : list_ave,\n",
    "        \"mse_0\"   : list_0,\n",
    "        \"mse_40\"  : list_40,\n",
    "        \"mse_80\"  : list_80,\n",
    "        \"mse_120\" : list_120,\n",
    "        \"mse_160\" : list_160}\n",
    "df=pd.DataFrame(data)\n",
    "df.to_excel(\"./model2.xlsx\")\n",
    "df = df.sort_values(by='mse_average',inplace=False,ascending=True).head(num_to_test)\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc2f59-25ec-4f2a-975d-a92d23aa4e63",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
