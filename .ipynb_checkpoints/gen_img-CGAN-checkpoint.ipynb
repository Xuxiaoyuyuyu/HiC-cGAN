{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314af022-be55-487f-95ab-b0f2fbd686a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test.py\n",
    "import IPython.display as display\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from models import ConvolutionalBlock, ResidualBlock\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import os\n",
    "import hickle as hkl\n",
    "import shutil\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "test_data_path = './data/GM12878/test_data_half.hkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a914c35-7c93-43ca-9f03-916891752cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, kernel_size=3, n_channels=64, n_blocks=5):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 第一个卷积块\n",
    "        self.conv_block1 = ConvolutionalBlock(in_channels=6, out_channels=n_channels, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation='relu')\n",
    "\n",
    "        # 一系列残差模块, 每个残差模块包含一个跳连\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(kernel_size=kernel_size, n_channels=n_channels) for i in range(n_blocks)])\n",
    "\n",
    "        # 第二个卷积块\n",
    "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              batch_norm=True, activation=None)\n",
    "\n",
    "        # 最后3个卷积模块\n",
    "        self.conv_block3 = ConvolutionalBlock(in_channels=n_channels, out_channels=128, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation=None)\n",
    "        self.conv_block4 = ConvolutionalBlock(in_channels=128, out_channels=256, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation=None)\n",
    "        self.conv_block5 = ConvolutionalBlock(in_channels=256, out_channels=1, kernel_size=1,\n",
    "                                              batch_norm=False, activation='tanh')\n",
    "\n",
    "    def forward(self, lr_imgs):\n",
    "        output = self.conv_block1(lr_imgs)  # (batch_size, 1, 40, 40)\n",
    "        residual = output\n",
    "        output = self.residual_blocks(output)\n",
    "        output = self.conv_block2(output)\n",
    "        output = output + residual\n",
    "        output = self.conv_block3(output)\n",
    "        output = self.conv_block4(output)\n",
    "        sr_imgs = self.conv_block5(output)\n",
    "        return sr_imgs\n",
    "\n",
    "def make_input(imgs, distances): #imgs batchsize*1*40*40     distances batchsize*5\n",
    "    dis = distances.unsqueeze(2).unsqueeze(3)\n",
    "    dis = dis.repeat(1,1,40,40)\n",
    "    data_input = torch.cat((imgs,dis),1)\n",
    "    return data_input\n",
    "\n",
    "\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        lo, hi, distance_chrome = hkl.load(test_data_path)\n",
    "        lo = lo.squeeze()\n",
    "        hi = hi.squeeze()\n",
    "        lo = np.expand_dims(lo,axis=1)\n",
    "        hi = np.expand_dims(hi,axis=1)\n",
    "        self.sample_list = []\n",
    "        for i in range(len(lo)):\n",
    "            lr = lo[i]\n",
    "            hr = hi[i]\n",
    "            dist = distance_chrome[i][0]\n",
    "            label_one_hot = torch.zeros(5)\n",
    "            label_one_hot[int(-abs((distance_chrome[i][0]))/40)]=1\n",
    "            chrom = distance_chrome[i][1]\n",
    "            self.sample_list.append([lr, hr, label_one_hot, dist, chrom])\n",
    "        print(\"dataset loaded : \" + str(len(lo)) + '*' + str(len(lo[0])) + '*' + str(len(lo[0][0])) + '*' + str(len(lo[0][0][0])))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        (lr_img, hr_img, label_one_hot, distance, chromosome) = self.sample_list[i]\n",
    "        return lr_img, hr_img, label_one_hot, distance, chromosome\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08dc19db-348a-4cdf-ba8c-e4beb8c6ead4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded : 3173*1*40*40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv_block1): ConvolutionalBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (residual_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv_block1): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_block2): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv_block1): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_block2): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv_block1): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_block2): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv_block1): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_block2): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv_block1): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_block2): ConvolutionalBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_block2): ConvolutionalBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_block3): ConvolutionalBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conv_block4): ConvolutionalBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conv_block5): ConvolutionalBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(\"./model/best_checkpoint_epoch3840.pth\")\n",
    "test_dataset = testDataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=1,\n",
    "                                           pin_memory=True)\n",
    "generator = Generator(kernel_size=3,n_channels=64,n_blocks=5)\n",
    "generator = generator.to(device)\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ef6f86-c21d-44e4-a0c9-641308d1926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***生成结束***\n"
     ]
    }
   ],
   "source": [
    "def save_img(img, i, label):\n",
    "    img = img.squeeze().cpu()\n",
    "    img = img.numpy()\n",
    "    img = 127.5 * img + 127.5\n",
    "    \n",
    "    img = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
    "    red = img[:, :, 0]\n",
    "    white = 255-red\n",
    "    img[:, :, 1] = 255\n",
    "    img[:, :, 2] = 255\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    img.save('./test/' + str(i).zfill(3) + '_' + label + '.jpg')\n",
    "    \n",
    "shutil.rmtree('./test')\n",
    "os.mkdir('./test')\n",
    "cnt = 0\n",
    "for i, (lr_img, hr_img, label, distance, __) in enumerate(test_loader):\n",
    "    display.clear_output(wait=True)\n",
    "    if not distance == 0 :\n",
    "        continue\n",
    "    cnt = cnt + 1\n",
    "    print(\"***开始生成***\")\n",
    "    print(\"正在处理：\" + str(i) + \"/\" + str(len(test_dataset)))\n",
    "    lr_img = lr_img.type(torch.FloatTensor).to(device)\n",
    "    hr_img = hr_img.type(torch.FloatTensor).to(device)\n",
    "    label = label.to(device)\n",
    "    G_input = make_input(lr_img, label)\n",
    "    with torch.no_grad():\n",
    "        sr_img = generator(G_input.detach())\n",
    "\n",
    "    save_img(lr_img, cnt, 'lr')\n",
    "    save_img(hr_img, cnt, 'hr')\n",
    "    save_img(sr_img, cnt, 'sr')\n",
    "\n",
    "print(\"***生成结束***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81ed0a-7e04-4ab9-910b-dfc4e141771a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
