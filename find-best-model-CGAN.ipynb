{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d01dcce-afc1-4b4f-977e-b040c81b54c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### -*- encoding: utf-8 -*-\n",
    "import IPython.display as display\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from models import ConvolutionalBlock, ResidualBlock\n",
    "from torch import nn\n",
    "import hickle as hkl\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        lo, hi, distance_chrome = hkl.load('./data/GM12878/test_data_half.hkl')\n",
    "        lo = lo.squeeze()\n",
    "        hi = hi.squeeze()\n",
    "        lo = np.expand_dims(lo,axis=1)\n",
    "        hi = np.expand_dims(hi,axis=1)\n",
    "        self.sample_list = []\n",
    "        for i in range(len(lo)):\n",
    "            lr = lo[i]\n",
    "            hr = hi[i]\n",
    "            dist = abs(distance_chrome[i][0])\n",
    "            label_one_hot = torch.zeros(5)\n",
    "            label_one_hot[int(dist/40)]=1\n",
    "            chrom = distance_chrome[i][1]\n",
    "            self.sample_list.append([lr, hr, label_one_hot, dist, chrom])\n",
    "        print(\"dataset loaded : \" + str(len(lo)) + '*' + str(len(lo[0])) + '*' + str(len(lo[0][0])) + '*' + str(len(lo[0][0][0])))\n",
    "    def __getitem__(self, i):\n",
    "        (lr_img, hr_img, label_one_hot, distance, chromosome) = self.sample_list[i]\n",
    "        return lr_img, hr_img, label_one_hot, distance, chromosome\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, kernel_size=3, n_channels=64, n_blocks=5):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv_block1 = ConvolutionalBlock(in_channels=6, out_channels=n_channels, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation='relu')\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(kernel_size=kernel_size, n_channels=n_channels) for i in range(n_blocks)])\n",
    "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              batch_norm=True, activation=None)\n",
    "        self.conv_block3 = ConvolutionalBlock(in_channels=n_channels, out_channels=128, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation=None)\n",
    "        self.conv_block4 = ConvolutionalBlock(in_channels=128, out_channels=256, kernel_size=kernel_size,\n",
    "                                              batch_norm=False, activation=None)\n",
    "        self.conv_block5 = ConvolutionalBlock(in_channels=256, out_channels=1, kernel_size=1,\n",
    "                                              batch_norm=False, activation='tanh')\n",
    "    def forward(self, lr_imgs):\n",
    "        output = self.conv_block1(lr_imgs)  # (batch_size, 1, 40, 40)\n",
    "        residual = output\n",
    "        output = self.residual_blocks(output)\n",
    "        output = self.conv_block2(output)\n",
    "        output = output + residual\n",
    "        output = self.conv_block3(output)\n",
    "        output = self.conv_block4(output)\n",
    "        sr_imgs = self.conv_block5(output)\n",
    "        return sr_imgs\n",
    "\n",
    "def make_input(imgs, distances): #imgs batchsize*1*40*40     distances batchsize*5\n",
    "    dis = distances.unsqueeze(2).unsqueeze(3)\n",
    "    dis = dis.repeat(1,1,40,40)\n",
    "    data_input = torch.cat((imgs,dis),1)\n",
    "    return data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cce27c1-5045-4901-a7a7-8f66ba8b7358",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded : 3173*1*40*40\n"
     ]
    }
   ],
   "source": [
    "test_dataset = testDataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1,\n",
    "                                               pin_memory=True)\n",
    "generator = Generator(kernel_size=3,n_channels=64,n_blocks=5)\n",
    "generator = generator.to(device)\n",
    "mse_loss_criterion = nn.MSELoss()\n",
    "mse_loss_criterion = mse_loss_criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f34551-c056-46d5-8a18-bb5a085b2020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***开始测试***\n",
      "正在测试模型：20/20\n",
      "正在处理样本 ： 3173/3173\n",
      "MSE_AVG = 0.060361207  PSNR_AVG = 20.567508585190602  SSIM_AVG = 0.2835752793499226\n",
      "MSE_0   = 0.017268976  PSNR_0   = 24.221341487281993  SSIM_0   = 0.5493183538855767\n",
      "MSE_40  = 0.020786356  PSNR_40  = 23.716214049159284  SSIM_40  = 0.2574529514092742\n",
      "MSE_80  = 0.031026667  PSNR_80  = 21.480572533032053  SSIM_80  = 0.23161828928022926\n",
      "MSE_120 = 0.16813369  PSNR_120 = 14.099685757831402  SSIM_120 = 0.21531540741854288\n",
      "MSE_160 = 0.06862084  PSNR_160 = 18.993057109872762  SSIM_160 = 0.1506556700942406\n",
      "***测试结束***\n"
     ]
    }
   ],
   "source": [
    "num_to_test = 20\n",
    "df = pd.read_excel(\"./log_cgan4.xls\", usecols=[0, 1])\n",
    "df = df.sort_values(by='MSE损失',inplace=False,ascending=True).head(num_to_test)\n",
    "mse_list_train = df[\"MSE损失\"].values.tolist()\n",
    "epoch_list = df[\"epoch\"].values.tolist()\n",
    "list_ave = []\n",
    "list_0 = []\n",
    "list_40 = []\n",
    "list_80 = []\n",
    "list_120 = []\n",
    "list_160 = []\n",
    "cnt = 0\n",
    "for epoch in epoch_list :\n",
    "    model_path = \"./result_cgan4/best_checkpoint_epoch\" + str(epoch).zfill(4) + \".pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        break\n",
    "    checkpoint = torch.load(model_path)\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    generator = generator.eval()\n",
    "\n",
    "    ave_mse = []\n",
    "    MSE_0 = []\n",
    "    MSE_40 = []\n",
    "    MSE_80 = []\n",
    "    MSE_120 = []\n",
    "    MSE_160 = []\n",
    "    ave_psnr = []\n",
    "    PSNR_0 = []\n",
    "    PSNR_40 = []\n",
    "    PSNR_80 = []\n",
    "    PSNR_120 = []\n",
    "    PSNR_160 = []\n",
    "    ave_ssim = []\n",
    "    SSIM_0 = []\n",
    "    SSIM_40 = []\n",
    "    SSIM_80 = []\n",
    "    SSIM_120 = []\n",
    "    SSIM_160 = []\n",
    "    for i, (lr_img, hr_img, label, distance, chrom) in enumerate(test_loader):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"***开始测试***\")\n",
    "        print(\"正在测试模型：\" + str(cnt) + \"/\" + str(num_to_test))\n",
    "        print(\"正在处理样本 ： \" + str(i+1) + \"/\"+str(len(test_dataset)))\n",
    "        print(\"MSE_AVG = \" + str(np.mean(ave_mse))  + \"  PSNR_AVG = \" + str(np.mean(ave_psnr))+ \"  SSIM_AVG = \" + str(np.mean(ave_ssim)))\n",
    "        print(\"MSE_0   = \" + str(np.mean(MSE_0))  + \"  PSNR_0   = \" + str(np.mean(PSNR_0))+ \"  SSIM_0   = \" + str(np.mean(SSIM_0)))\n",
    "        print(\"MSE_40  = \" + str(np.mean(MSE_40)) + \"  PSNR_40  = \" + str(np.mean(PSNR_40))+ \"  SSIM_40  = \" + str(np.mean(SSIM_40)))\n",
    "        print(\"MSE_80  = \" + str(np.mean(MSE_80)) + \"  PSNR_80  = \" + str(np.mean(PSNR_80))+ \"  SSIM_80  = \" + str(np.mean(SSIM_80)))\n",
    "        print(\"MSE_120 = \" + str(np.mean(MSE_120))+ \"  PSNR_120 = \" + str(np.mean(PSNR_120))+ \"  SSIM_120 = \" + str(np.mean(SSIM_120)))\n",
    "        print(\"MSE_160 = \" + str(np.mean(MSE_160))+ \"  PSNR_160 = \" + str(np.mean(PSNR_160))+ \"  SSIM_160 = \" + str(np.mean(SSIM_160)))\n",
    "        lr_img = lr_img.type(torch.FloatTensor).to(device)\n",
    "        hr_img = hr_img.type(torch.FloatTensor).to(device)\n",
    "        label = label.to(device)\n",
    "        G_input = make_input(lr_img, label)\n",
    "        with torch.no_grad():\n",
    "            sr_img = generator(G_input.detach())\n",
    "        mse = mse_loss_criterion(sr_img , hr_img).to('cpu')\n",
    "        sr_img = sr_img.squeeze().to(\"cpu\").numpy()\n",
    "        hr_img = hr_img.squeeze().to(\"cpu\").numpy()\n",
    "        \n",
    "        psnr = peak_signal_noise_ratio(hr_img, sr_img)\n",
    "        ssim = structural_similarity(hr_img, sr_img)\n",
    "    \n",
    "        ave_mse.append(mse)\n",
    "        ave_psnr.append(psnr)\n",
    "        ave_ssim.append(ssim)\n",
    "        if abs(distance) == 0:\n",
    "            MSE_0.append(mse)\n",
    "            PSNR_0.append(psnr)\n",
    "            SSIM_0.append(ssim)\n",
    "        elif abs(distance) == 40:\n",
    "            MSE_40.append(mse)\n",
    "            PSNR_40.append(psnr)\n",
    "            SSIM_40.append(ssim)\n",
    "        elif abs(distance) == 80:\n",
    "            MSE_80.append(mse)\n",
    "            PSNR_80.append(psnr)\n",
    "            SSIM_80.append(ssim)\n",
    "        elif abs(distance) == 120:\n",
    "            MSE_120.append(mse)\n",
    "            PSNR_120.append(psnr)\n",
    "            SSIM_120.append(ssim)\n",
    "        elif abs(distance) == 160:\n",
    "            MSE_160.append(mse)\n",
    "            PSNR_160.append(psnr)\n",
    "            SSIM_160.append(ssim)\n",
    "    list_ave.append(np.mean(ave_mse))\n",
    "    list_0.append(np.mean(MSE_0))\n",
    "    list_40.append(np.mean(MSE_40))\n",
    "    list_80.append(np.mean(MSE_80))\n",
    "    list_120.append(np.mean(MSE_120))\n",
    "    list_160.append(np.mean(MSE_160))\n",
    "print(\"***测试结束***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2694e860-bf48-429d-b390-56962cba270d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch  mse_train  mse_test     mse_0    mse_40    mse_80   mse_120   mse_160\n",
      "   350   0.023942  0.030828  0.024474  0.025532  0.024071  0.039380  0.041526\n",
      "   107   0.022577  0.032742  0.023131  0.024741  0.034988  0.023786  0.058327\n",
      "   262   0.023227  0.034745  0.020599  0.026460  0.021168  0.051144  0.056029\n",
      "   101   0.022371  0.035308  0.030408  0.020239  0.025251  0.044163  0.057905\n",
      "   158   0.024053  0.040380  0.039550  0.039290  0.033946  0.049828  0.039456\n",
      "   256   0.022671  0.040932  0.030568  0.030481  0.030490  0.077777  0.036270\n",
      "   303   0.022210  0.042930  0.026186  0.058267  0.025590  0.050601  0.054866\n",
      "   424   0.022793  0.043140  0.033827  0.021147  0.033731  0.078778  0.049717\n",
      "   221   0.023099  0.044235  0.059389  0.070482  0.023049  0.029547  0.037320\n",
      "   425   0.022146  0.045731  0.022478  0.043221  0.071793  0.045295  0.046627\n",
      "    85   0.024414  0.048719  0.032531  0.024722  0.054262  0.058875  0.075285\n",
      "   264   0.019699  0.053782  0.025173  0.057369  0.052566  0.058029  0.077582\n",
      "   257   0.023463  0.055134  0.023590  0.046098  0.035758  0.032399  0.141926\n",
      "   114   0.024605  0.060347  0.017267  0.020786  0.031027  0.168134  0.068621\n",
      "   263   0.022489  0.061578  0.053616  0.035748  0.139572  0.027774  0.050818\n",
      "   112   0.023193  0.068533  0.173060  0.045257  0.040582  0.030360  0.049227\n",
      "   265   0.020436  0.071658  0.064890  0.027872  0.074433  0.094032  0.099434\n",
      "   106   0.023917  0.077845  0.208629  0.056204  0.038133  0.044445  0.036029\n",
      "   392   0.023452  0.080727  0.040189  0.176318  0.079775  0.039535  0.066243\n",
      "   113   0.022882  0.209863  0.423032  0.135308  0.174002  0.152633  0.156039\n"
     ]
    }
   ],
   "source": [
    "data = {\"epoch\" : epoch_list[0:cnt],\n",
    "        \"mse_train\" :mse_list_train[0:cnt],\n",
    "        \"mse_test\" : list_ave,\n",
    "        \"mse_0\"   : list_0,\n",
    "        \"mse_40\"  : list_40,\n",
    "        \"mse_80\"  : list_80,\n",
    "        \"mse_120\" : list_120,\n",
    "        \"mse_160\" : list_160}\n",
    "df=pd.DataFrame(data)\n",
    "df.to_excel(\"./model.xlsx\")\n",
    "df = df.sort_values(by='mse_test',inplace=False,ascending=True).head(num_to_test)\n",
    "print(df.head(100).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc2f59-25ec-4f2a-975d-a92d23aa4e63",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
